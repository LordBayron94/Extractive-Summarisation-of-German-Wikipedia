{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LUNYGXiibH8Z",
    "outputId": "57ad2638-03a9-4803-958a-ebfa261f7c71"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dorian\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dorian\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd, re, nltk, numpy as np, string\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "german_stop_words = stopwords.words('german')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "CPeiTG6Zqa5O",
    "outputId": "f2bcf323-ba0f-4c0f-9fb6-00661c8b1c27"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Minghella war der Sohn italienisch-schottische...</td>\n",
       "      <td>Anthony Minghella, CBE war ein britischer Film...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ende der 1940er Jahre wurde eine erste Auteur-...</td>\n",
       "      <td>Die Auteur-Theorie ist eine Filmtheorie und di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Al Pacino, geboren in Manhattan, ist der Sohn ...</td>\n",
       "      <td>Alfredo James \"Al\" Pacino ist ein US-amerikani...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Der Name der Alkalimetalle leitet sich von dem...</td>\n",
       "      <td>Als Alkalimetalle werden die chemischen Elemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Die Arbeit ist bereits seit dem Altertum Gegen...</td>\n",
       "      <td>Das deutsche Arbeitsrecht ist ein Rechtsgebiet...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  Minghella war der Sohn italienisch-schottische...   \n",
       "1  Ende der 1940er Jahre wurde eine erste Auteur-...   \n",
       "2  Al Pacino, geboren in Manhattan, ist der Sohn ...   \n",
       "3  Der Name der Alkalimetalle leitet sich von dem...   \n",
       "4  Die Arbeit ist bereits seit dem Altertum Gegen...   \n",
       "\n",
       "                                             summary  \n",
       "0  Anthony Minghella, CBE war ein britischer Film...  \n",
       "1  Die Auteur-Theorie ist eine Filmtheorie und di...  \n",
       "2  Alfredo James \"Al\" Pacino ist ein US-amerikani...  \n",
       "3  Als Alkalimetalle werden die chemischen Elemen...  \n",
       "4  Das deutsche Arbeitsrecht ist ein Rechtsgebiet...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('G:/Extractive-Summarisation-of-German-Wikipedia/dataset/data_train.csv', encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "z6ZeSHqePu0s"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('G:/Extractive-Summarisation-of-German-Wikipedia/dataset/data_class.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['source', 'summary', 'keywords'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-e6d4fe69fcf6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m#return TfidfVec.fit_transform(df)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msource1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msource1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcalc_importance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mH:\\anaconda\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   4136\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4137\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4138\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4140\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-33-e6d4fe69fcf6>\u001b[0m in \u001b[0;36mcalc_importance\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mTfidfVec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"german\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mTfidfVec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\anaconda\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36m__eq__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[1;31m# Scalar other.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misscalarlike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    219\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "def calc_importance(df):\n",
    "    german_stop_words = stopwords.words('german')\n",
    "    TfidfVec = TfidfVectorizer()\n",
    "    tokens = sent_tokenize(df, language=\"german\")\n",
    "    if TfidfVec.fit_transform(tokens) == NaN:\n",
    "        print(9)\n",
    "    else:    \n",
    "        print (TfidfVec.fit_transform(tokens))\n",
    "    #return TfidfVec.fit_transform(df)\n",
    "\n",
    "df.source1 = df.source1.apply(calc_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "1Wjz5XXkqplN"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'source'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mH:\\anaconda\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'source'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-c66ec460c227>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfiltered_text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"source\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"source\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremove_stopwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mH:\\anaconda\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3023\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3024\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3025\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\anaconda\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'source'"
     ]
    }
   ],
   "source": [
    "stopword_list = nltk.corpus.stopwords.words('german')\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    filtered_words = [word for word in nltk.word_tokenize(text) if word not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_words)\n",
    "    return filtered_text\n",
    "\n",
    "df[\"source\"] = df[\"source\"].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRklrUC_gvHS"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "b-8ELYhjrN2g"
   },
   "outputs": [],
   "source": [
    "def sort_coo(coo_matrix):\n",
    "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
    "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
    "\n",
    "def extract_topn_from_vector(feature_names, sorted_items, topn=10):\n",
    "    \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n",
    "    \n",
    "    #use only topn items from vector\n",
    "    sorted_items = sorted_items[:topn]\n",
    "\n",
    "    score_vals = []\n",
    "    feature_vals = []\n",
    "\n",
    "    for idx, score in sorted_items:\n",
    "        fname = feature_names[idx]\n",
    "        \n",
    "        #keep track of feature name and its corresponding score\n",
    "        score_vals.append(round(score, 3))\n",
    "        feature_vals.append(feature_names[idx])\n",
    "\n",
    "    #create a tuples of feature,score\n",
    "    #results = zip(feature_vals,score_vals)\n",
    "    results= {}\n",
    "    for idx in range(len(feature_vals)):\n",
    "        results[feature_vals[idx]]=score_vals[idx]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "bo0xTWU3q7BY"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "german_stop_words = stopwords.words('german')\n",
    "\n",
    "cv = CountVectorizer(max_df=0.85,stop_words=german_stop_words, max_features=10000)\n",
    "word_count_vector = cv.fit_transform(df['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "f4cFJhq3rAlJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "tfidf_transformer.fit(word_count_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "q-CZ7KYBrDW0"
   },
   "outputs": [],
   "source": [
    "tfidf_transformer.idf_\n",
    "feature_names=cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Z0SYmyCVrRHE"
   },
   "outputs": [],
   "source": [
    "#doc = df['source'][2568]\n",
    "def get_kew(df):\n",
    "    kw=[]\n",
    "    tf_idf_vector=tfidf_transformer.transform(cv.transform([df]))\n",
    "    sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
    "    keywords = extract_topn_from_vector(feature_names,sorted_items,10)\n",
    "    for k in keywords:\n",
    "        kw.append(k)\n",
    "    return kw\n",
    "\n",
    "df['keywords'] = df['source'].apply(get_kew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JuTBnQQfiOek"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "9El64oNvEctZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Getting s as pandas series which has split on full stop and new sentence a new line         \n",
    "s = df[\"source\"].apply(lambda x : sent_tokenize(x)).apply(pd.Series,1).stack()\n",
    "s.index = s.index.droplevel(-1) # to line up with df's index\n",
    "s.name = 'source' # needs a name to join\n",
    "\n",
    "x=s.to_frame(name='source1')\n",
    "\n",
    "# Joining should ideally get me proper output. But I am getting original dataframe instead of split one.\n",
    "df = df.join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cellView": "code",
    "id": "A70QJJzEr_hQ"
   },
   "outputs": [],
   "source": [
    "#@title Default title text\n",
    "def CapWords(df):\n",
    "    return sum(1 for c in df if c.isupper())\n",
    "\n",
    "def W_sourceSummary(df, df2):\n",
    "    text2 = df2\n",
    "    text2 = text2.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = sent_tokenize(df, language = \"german\")\n",
    "    tok2 = word_tokenize(text2, language = \"german\")\n",
    "    for s in tokens:\n",
    "      #print (s)\n",
    "      return len(set(s.split()).intersection(set(tok2)))\n",
    "\n",
    "def W_sourceKeywords(df, df2):\n",
    "    df.lower()\n",
    "    text2 = df2\n",
    "    text2 = text2.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = sent_tokenize(df, language = \"german\")\n",
    "    tok2 = word_tokenize(text2, language = \"german\")\n",
    "    for s in tokens:\n",
    "        return len(set(s.split()).intersection(set(tok2)))\n",
    "\n",
    "def listToString(df):\n",
    "    string = ' '.join([str(e) for e in df])\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "95Aplb4Otni1"
   },
   "outputs": [],
   "source": [
    "df['no_words_inSent_SS'] = df.apply(lambda x: W_sourceSummary(x['source1'], x['summary']), axis=1)\n",
    "df['keywords'] = df['keywords'].apply(listToString)\n",
    "df['no_words_inSent_SK'] = df.apply(lambda x: W_sourceKeywords(x['source1'], x['keywords']), axis=1)\n",
    "df['noCap_LetterWords_inSentence'] = df['source1'].apply(CapWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "id": "c8qbwiB4e8xD",
    "outputId": "4f1d78f3-7f8a-4b53-d10d-098daa8d3536"
   },
   "outputs": [],
   "source": [
    "german_stop_words = stopwords.words('german')\n",
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    "def LemTokens(tokens):\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words=german_stop_words)\n",
    "def cos_similarity(textlist):\n",
    "    tfidf = TfidfVec.fit_transform(textlist)\n",
    "    return (tfidf * tfidf.T).toarray()\n",
    "\n",
    "df[\"source\"] = df.apply(cos_similarity(df.source1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "P9JnIao8jNGO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Dorian\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.        0.0724038]\n",
      " [0.0724038 1.       ]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1. 0.]\n",
      " [0. 1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1. 0.]\n",
      " [0. 1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.         0.07433426]\n",
      " [0.07433426 1.        ]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.         0.04642928]\n",
      " [0.04642928 1.        ]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.         0.10371551]\n",
      " [0.10371551 1.        ]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.        0.0595144]\n",
      " [0.0595144 1.       ]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1. 0.]\n",
      " [0. 1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1. 0.]\n",
      " [0. 1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1. 0.]\n",
      " [0. 1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1. 0.]\n",
      " [0. 1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1. 0.]\n",
      " [0. 1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1. 0.]\n",
      " [0. 1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1. 0.]\n",
      " [0. 1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1. 0.]\n",
      " [0. 1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1. 0.]\n",
      " [0. 1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1. 0.]\n",
      " [0. 1.]]\n",
      "[[1.]]\n",
      "[[1. 0.]\n",
      " [0. 1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-e66567d15439>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;31m#get_docs(df['source'][0])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sim_sent'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'source1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_docs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mH:\\anaconda\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   4136\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4137\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4138\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4140\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-e66567d15439>\u001b[0m in \u001b[0;36mget_docs\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"german\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mlst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_tuples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msimilar_sent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcos_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mdoc_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"s\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-e66567d15439>\u001b[0m in \u001b[0;36mcos_similarity\u001b[1;34m(textlist)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mTfidfVec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLemNormalize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgerman_stop_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcos_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtextlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mTfidfVec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtextlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m#        continue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\anaconda\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1848\u001b[0m         \"\"\"\n\u001b[0;32m   1849\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1850\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1851\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m         \u001b[1;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\anaconda\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1201\u001b[0m         \u001b[0mmax_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1203\u001b[1;33m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0m\u001b[0;32m   1204\u001b[0m                                           self.fixed_vocabulary_)\n\u001b[0;32m   1205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\anaconda\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1132\u001b[0m             \u001b[0mvocabulary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1133\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1134\u001b[1;33m                 raise ValueError(\"empty vocabulary; perhaps the documents only\"\n\u001b[0m\u001b[0;32m   1135\u001b[0m                                  \" contain stop words\")\n\u001b[0;32m   1136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet') # first-time use only\n",
    "german_stop_words = stopwords.words('german')\n",
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    "def LemTokens(tokens):\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words=german_stop_words)\n",
    "def cos_similarity(textlist):\n",
    "    if TfidfVec.fit_transform(textlist)==None:\n",
    "        return 0\n",
    "#        continue\n",
    "    else:\n",
    "        tfidf = TfidfVec.fit_transform(textlist)\n",
    "        return (tfidf * tfidf.T).toarray()\n",
    "\n",
    "def get_docs(df):\n",
    "    threshold = 0.15\n",
    "    doc = sent_tokenize(df, language=\"german\")\n",
    "    lst, output_tuples, similar_sent = [], [], [] \n",
    "    arr = cos_similarity(doc)\n",
    "    print (arr)\n",
    "    doc_names = [\"s\"+str(s) for s in range(0, len(doc), 1)]\n",
    "    for row in range(len(arr)):\n",
    "        lst = [row+1+idx for idx, num in \\\n",
    "                  enumerate(arr[row, row+1:]) if num >= threshold]\n",
    "        [(output_tuples.append((doc[row], doc[item]))) for item in lst]\n",
    "    for tup in output_tuples:\n",
    "        for sent in tup:\n",
    "            similar_sent.append(sent)\n",
    "    for sent in doc:\n",
    "        if sent in set(doc).intersection(set(similar_sent)):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "#get_docs(df['source'][0])\n",
    "df['sim_sent'] = df['source1'].apply(get_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "iRqCQpC0I3I3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source1</th>\n",
       "      <th>no_words_inSent_SS</th>\n",
       "      <th>no_words_inSent_SK</th>\n",
       "      <th>noCap_LetterWords_inSentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Minghella Sohn italienisch-schottischer Eltern...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nach Schulabschluss studierte Universität Hul...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1978 drehte ersten Kurzfilm .</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Seit 1981 Autor Story Editor tätig .</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Er wurde Theaterstücken , Rundfunkhörspielen...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>Carl Sigmans Text erschien 1960er Jahren briti...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>Camillo Felgen alias Heinz Helmer verfasste de...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>Zahlreiche Interpreten sangen 1964 Lied franzo...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>Von Letzterer stammt spanischsprachige Fassung...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>In 1970er Jahren nahmen mehrere prominente Sä...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3513935 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 source1  no_words_inSent_SS  \\\n",
       "0      Minghella Sohn italienisch-schottischer Eltern...                   1   \n",
       "0      Nach Schulabschluss studierte Universität Hul...                   0   \n",
       "0                          1978 drehte ersten Kurzfilm .                   0   \n",
       "0                  Seit 1981 Autor Story Editor tätig .                   0   \n",
       "0      Er wurde Theaterstücken , Rundfunkhörspielen...                   0   \n",
       "...                                                  ...                 ...   \n",
       "99999  Carl Sigmans Text erschien 1960er Jahren briti...                   0   \n",
       "99999  Camillo Felgen alias Heinz Helmer verfasste de...                   5   \n",
       "99999  Zahlreiche Interpreten sangen 1964 Lied franzo...                   1   \n",
       "99999  Von Letzterer stammt spanischsprachige Fassung...                   2   \n",
       "99999  In 1970er Jahren nahmen mehrere prominente Sä...                   5   \n",
       "\n",
       "       no_words_inSent_SK  noCap_LetterWords_inSentence  \n",
       "0                       0                             7  \n",
       "0                       0                             6  \n",
       "0                       0                             1  \n",
       "0                       0                             4  \n",
       "0                       0                             9  \n",
       "...                   ...                           ...  \n",
       "99999                   0                             7  \n",
       "99999                   1                            12  \n",
       "99999                   1                            11  \n",
       "99999                   1                             6  \n",
       "99999                   1                            13  \n",
       "\n",
       "[3513935 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "df.drop(['source', 'summary', 'keywords'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "ZKDqQ6YK2AiQ"
   },
   "outputs": [],
   "source": [
    "df3.to_csv('G:/Extractive-Summarisation-of-German-Wikipedia/dataset/data_class.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('G:/Extractive-Summarisation-of-German-Wikipedia/dataset/data_features.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 18310\n",
    "df2 = df2.head(df2.shape[0] -N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.concat([df.reset_index(drop=True),df2.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>source1</th>\n",
       "      <th>no_words_inSent_SS</th>\n",
       "      <th>no_words_inSent_SK</th>\n",
       "      <th>noCap_LetterWords_inSentence</th>\n",
       "      <th>sim_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Minghella Sohn italienisch-schottischer Eltern...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>[1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Nach Schulabschluss studierte Universität Hul...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1978 drehte ersten Kurzfilm .</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Seit 1981 Autor Story Editor tätig .</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Er wurde Theaterstücken , Rundfunkhörspielen...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3513930</th>\n",
       "      <td>99999</td>\n",
       "      <td>Carl Sigmans Text erschien 1960er Jahren briti...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3513931</th>\n",
       "      <td>99999</td>\n",
       "      <td>Camillo Felgen alias Heinz Helmer verfasste de...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3513932</th>\n",
       "      <td>99999</td>\n",
       "      <td>Zahlreiche Interpreten sangen 1964 Lied franzo...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3513933</th>\n",
       "      <td>99999</td>\n",
       "      <td>Von Letzterer stammt spanischsprachige Fassung...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3513934</th>\n",
       "      <td>99999</td>\n",
       "      <td>In 1970er Jahren nahmen mehrere prominente Sä...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3513935 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0                                            source1  \\\n",
       "0                 0  Minghella Sohn italienisch-schottischer Eltern...   \n",
       "1                 0  Nach Schulabschluss studierte Universität Hul...   \n",
       "2                 0                      1978 drehte ersten Kurzfilm .   \n",
       "3                 0              Seit 1981 Autor Story Editor tätig .   \n",
       "4                 0  Er wurde Theaterstücken , Rundfunkhörspielen...   \n",
       "...             ...                                                ...   \n",
       "3513930       99999  Carl Sigmans Text erschien 1960er Jahren briti...   \n",
       "3513931       99999  Camillo Felgen alias Heinz Helmer verfasste de...   \n",
       "3513932       99999  Zahlreiche Interpreten sangen 1964 Lied franzo...   \n",
       "3513933       99999  Von Letzterer stammt spanischsprachige Fassung...   \n",
       "3513934       99999  In 1970er Jahren nahmen mehrere prominente Sä...   \n",
       "\n",
       "         no_words_inSent_SS  no_words_inSent_SK  noCap_LetterWords_inSentence  \\\n",
       "0                         1                   0                             7   \n",
       "1                         0                   0                             6   \n",
       "2                         0                   0                             1   \n",
       "3                         0                   0                             4   \n",
       "4                         0                   0                             9   \n",
       "...                     ...                 ...                           ...   \n",
       "3513930                   0                   0                             7   \n",
       "3513931                   5                   1                            12   \n",
       "3513932                   1                   1                            11   \n",
       "3513933                   2                   1                             6   \n",
       "3513934                   5                   1                            13   \n",
       "\n",
       "        sim_sent  \n",
       "0             [1  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "...          ...  \n",
       "3513930        1  \n",
       "3513931        0  \n",
       "3513932        1  \n",
       "3513933        0  \n",
       "3513934        1  \n",
       "\n",
       "[3513935 rows x 6 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean(df):\n",
    "    if re.search('\\[.*', df):\n",
    "       return re.sub('\\[', '', df)\n",
    "    elif  re.search('.*\\].*', df):\n",
    "        return re.sub('\\]', '', df)\n",
    "    else:\n",
    "        return df\n",
    "\n",
    "df3.sim_sent = df3.sim_sent.apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>source1</th>\n",
       "      <th>no_words_inSent_SS</th>\n",
       "      <th>no_words_inSent_SK</th>\n",
       "      <th>noCap_LetterWords_inSentence</th>\n",
       "      <th>sim_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Minghella Sohn italienisch-schottischer Eltern...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Nach Schulabschluss studierte Universität Hul...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1978 drehte ersten Kurzfilm .</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Seit 1981 Autor Story Editor tätig .</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Er wurde Theaterstücken , Rundfunkhörspielen...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3513930</th>\n",
       "      <td>99999</td>\n",
       "      <td>Carl Sigmans Text erschien 1960er Jahren briti...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3513931</th>\n",
       "      <td>99999</td>\n",
       "      <td>Camillo Felgen alias Heinz Helmer verfasste de...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3513932</th>\n",
       "      <td>99999</td>\n",
       "      <td>Zahlreiche Interpreten sangen 1964 Lied franzo...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3513933</th>\n",
       "      <td>99999</td>\n",
       "      <td>Von Letzterer stammt spanischsprachige Fassung...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3513934</th>\n",
       "      <td>99999</td>\n",
       "      <td>In 1970er Jahren nahmen mehrere prominente Sä...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3513935 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0                                            source1  \\\n",
       "0                 0  Minghella Sohn italienisch-schottischer Eltern...   \n",
       "1                 0  Nach Schulabschluss studierte Universität Hul...   \n",
       "2                 0                      1978 drehte ersten Kurzfilm .   \n",
       "3                 0              Seit 1981 Autor Story Editor tätig .   \n",
       "4                 0  Er wurde Theaterstücken , Rundfunkhörspielen...   \n",
       "...             ...                                                ...   \n",
       "3513930       99999  Carl Sigmans Text erschien 1960er Jahren briti...   \n",
       "3513931       99999  Camillo Felgen alias Heinz Helmer verfasste de...   \n",
       "3513932       99999  Zahlreiche Interpreten sangen 1964 Lied franzo...   \n",
       "3513933       99999  Von Letzterer stammt spanischsprachige Fassung...   \n",
       "3513934       99999  In 1970er Jahren nahmen mehrere prominente Sä...   \n",
       "\n",
       "         no_words_inSent_SS  no_words_inSent_SK  noCap_LetterWords_inSentence  \\\n",
       "0                         1                   0                             7   \n",
       "1                         0                   0                             6   \n",
       "2                         0                   0                             1   \n",
       "3                         0                   0                             4   \n",
       "4                         0                   0                             9   \n",
       "...                     ...                 ...                           ...   \n",
       "3513930                   0                   0                             7   \n",
       "3513931                   5                   1                            12   \n",
       "3513932                   1                   1                            11   \n",
       "3513933                   2                   1                             6   \n",
       "3513934                   5                   1                            13   \n",
       "\n",
       "        sim_sent  \n",
       "0              1  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "...          ...  \n",
       "3513930        1  \n",
       "3513931        0  \n",
       "3513932        1  \n",
       "3513933        0  \n",
       "3513934        1  \n",
       "\n",
       "[3513935 rows x 6 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.set_index(['source']).sim_sent.apply(pd.Series).stack()\\\n",
    ".reset_index(name = 'sim_sent').drop('level_2', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.assign(sim_sent=df2.sim_sent.str.split(\",\")).explode('sim_sent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2[['sim_sent']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>summary</th>\n",
       "      <th>keywords</th>\n",
       "      <th>source1</th>\n",
       "      <th>no_words_inSent_SS</th>\n",
       "      <th>no_words_inSent_SK</th>\n",
       "      <th>noCap_LetterWords_inSentence</th>\n",
       "      <th>sim_sent</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Minghella Sohn italienisch-schottischer Eltern...</td>\n",
       "      <td>Anthony Minghella, CBE war ein britischer Film...</td>\n",
       "      <td>oscar regie opera bbc film bestes fernsehserie...</td>\n",
       "      <td>Minghella Sohn italienisch-schottischer Eltern...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Minghella Sohn italienisch-schottischer Eltern...</td>\n",
       "      <td>Anthony Minghella, CBE war ein britischer Film...</td>\n",
       "      <td>oscar regie opera bbc film bestes fernsehserie...</td>\n",
       "      <td>Nach Schulabschluss studierte Universität Hul...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Minghella Sohn italienisch-schottischer Eltern...</td>\n",
       "      <td>Anthony Minghella, CBE war ein britischer Film...</td>\n",
       "      <td>oscar regie opera bbc film bestes fernsehserie...</td>\n",
       "      <td>1978 drehte ersten Kurzfilm .</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Minghella Sohn italienisch-schottischer Eltern...</td>\n",
       "      <td>Anthony Minghella, CBE war ein britischer Film...</td>\n",
       "      <td>oscar regie opera bbc film bestes fernsehserie...</td>\n",
       "      <td>Seit 1981 Autor Story Editor tätig .</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Minghella Sohn italienisch-schottischer Eltern...</td>\n",
       "      <td>Anthony Minghella, CBE war ein britischer Film...</td>\n",
       "      <td>oscar regie opera bbc film bestes fernsehserie...</td>\n",
       "      <td>Er wurde Theaterstücken , Rundfunkhörspielen...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7046175</th>\n",
       "      <td>Umberto Bindi 1960er-Jahren bekanntesten Vertr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[2, 2, 6, 6, 2, 0, 5, 2, 6, 0, 2, 0, 0, 0, 6, ...</td>\n",
       "      <td>[0, 0, 1, 1, 0, 0, 4, 1, 1, 0, 1, 0, 0, 0, 1, ...</td>\n",
       "      <td>[6, 7, 14, 7, 10, 9, 15, 18, 14, 1, 8, 1, 2, 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>99999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7046176</th>\n",
       "      <td>Umberto Bindi 1960er-Jahren bekanntesten Vertr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[2, 2, 6, 6, 2, 0, 5, 2, 6, 0, 2, 0, 0, 0, 6, ...</td>\n",
       "      <td>[0, 0, 1, 1, 0, 0, 4, 1, 1, 0, 1, 0, 0, 0, 1, ...</td>\n",
       "      <td>[6, 7, 14, 7, 10, 9, 15, 18, 14, 1, 8, 1, 2, 1...</td>\n",
       "      <td>1</td>\n",
       "      <td>99999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7046177</th>\n",
       "      <td>Umberto Bindi 1960er-Jahren bekanntesten Vertr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[2, 2, 6, 6, 2, 0, 5, 2, 6, 0, 2, 0, 0, 0, 6, ...</td>\n",
       "      <td>[0, 0, 1, 1, 0, 0, 4, 1, 1, 0, 1, 0, 0, 0, 1, ...</td>\n",
       "      <td>[6, 7, 14, 7, 10, 9, 15, 18, 14, 1, 8, 1, 2, 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>99999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7046178</th>\n",
       "      <td>Umberto Bindi 1960er-Jahren bekanntesten Vertr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[2, 2, 6, 6, 2, 0, 5, 2, 6, 0, 2, 0, 0, 0, 6, ...</td>\n",
       "      <td>[0, 0, 1, 1, 0, 0, 4, 1, 1, 0, 1, 0, 0, 0, 1, ...</td>\n",
       "      <td>[6, 7, 14, 7, 10, 9, 15, 18, 14, 1, 8, 1, 2, 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>99999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7046179</th>\n",
       "      <td>Umberto Bindi 1960er-Jahren bekanntesten Vertr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[2, 2, 6, 6, 2, 0, 5, 2, 6, 0, 2, 0, 0, 0, 6, ...</td>\n",
       "      <td>[0, 0, 1, 1, 0, 0, 4, 1, 1, 0, 1, 0, 0, 0, 1, ...</td>\n",
       "      <td>[6, 7, 14, 7, 10, 9, 15, 18, 14, 1, 8, 1, 2, 1...</td>\n",
       "      <td>1]</td>\n",
       "      <td>99999.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7046180 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    source  \\\n",
       "0        Minghella Sohn italienisch-schottischer Eltern...   \n",
       "1        Minghella Sohn italienisch-schottischer Eltern...   \n",
       "2        Minghella Sohn italienisch-schottischer Eltern...   \n",
       "3        Minghella Sohn italienisch-schottischer Eltern...   \n",
       "4        Minghella Sohn italienisch-schottischer Eltern...   \n",
       "...                                                    ...   \n",
       "7046175  Umberto Bindi 1960er-Jahren bekanntesten Vertr...   \n",
       "7046176  Umberto Bindi 1960er-Jahren bekanntesten Vertr...   \n",
       "7046177  Umberto Bindi 1960er-Jahren bekanntesten Vertr...   \n",
       "7046178  Umberto Bindi 1960er-Jahren bekanntesten Vertr...   \n",
       "7046179  Umberto Bindi 1960er-Jahren bekanntesten Vertr...   \n",
       "\n",
       "                                                   summary  \\\n",
       "0        Anthony Minghella, CBE war ein britischer Film...   \n",
       "1        Anthony Minghella, CBE war ein britischer Film...   \n",
       "2        Anthony Minghella, CBE war ein britischer Film...   \n",
       "3        Anthony Minghella, CBE war ein britischer Film...   \n",
       "4        Anthony Minghella, CBE war ein britischer Film...   \n",
       "...                                                    ...   \n",
       "7046175                                                NaN   \n",
       "7046176                                                NaN   \n",
       "7046177                                                NaN   \n",
       "7046178                                                NaN   \n",
       "7046179                                                NaN   \n",
       "\n",
       "                                                  keywords  \\\n",
       "0        oscar regie opera bbc film bestes fernsehserie...   \n",
       "1        oscar regie opera bbc film bestes fernsehserie...   \n",
       "2        oscar regie opera bbc film bestes fernsehserie...   \n",
       "3        oscar regie opera bbc film bestes fernsehserie...   \n",
       "4        oscar regie opera bbc film bestes fernsehserie...   \n",
       "...                                                    ...   \n",
       "7046175                                                NaN   \n",
       "7046176                                                NaN   \n",
       "7046177                                                NaN   \n",
       "7046178                                                NaN   \n",
       "7046179                                                NaN   \n",
       "\n",
       "                                                   source1  \\\n",
       "0        Minghella Sohn italienisch-schottischer Eltern...   \n",
       "1        Nach Schulabschluss studierte Universität Hul...   \n",
       "2                            1978 drehte ersten Kurzfilm .   \n",
       "3                    Seit 1981 Autor Story Editor tätig .   \n",
       "4        Er wurde Theaterstücken , Rundfunkhörspielen...   \n",
       "...                                                    ...   \n",
       "7046175                                                NaN   \n",
       "7046176                                                NaN   \n",
       "7046177                                                NaN   \n",
       "7046178                                                NaN   \n",
       "7046179                                                NaN   \n",
       "\n",
       "                                        no_words_inSent_SS  \\\n",
       "0                                                        1   \n",
       "1                                                        0   \n",
       "2                                                        0   \n",
       "3                                                        0   \n",
       "4                                                        0   \n",
       "...                                                    ...   \n",
       "7046175  [2, 2, 6, 6, 2, 0, 5, 2, 6, 0, 2, 0, 0, 0, 6, ...   \n",
       "7046176  [2, 2, 6, 6, 2, 0, 5, 2, 6, 0, 2, 0, 0, 0, 6, ...   \n",
       "7046177  [2, 2, 6, 6, 2, 0, 5, 2, 6, 0, 2, 0, 0, 0, 6, ...   \n",
       "7046178  [2, 2, 6, 6, 2, 0, 5, 2, 6, 0, 2, 0, 0, 0, 6, ...   \n",
       "7046179  [2, 2, 6, 6, 2, 0, 5, 2, 6, 0, 2, 0, 0, 0, 6, ...   \n",
       "\n",
       "                                        no_words_inSent_SK  \\\n",
       "0                                                        0   \n",
       "1                                                        0   \n",
       "2                                                        0   \n",
       "3                                                        0   \n",
       "4                                                        0   \n",
       "...                                                    ...   \n",
       "7046175  [0, 0, 1, 1, 0, 0, 4, 1, 1, 0, 1, 0, 0, 0, 1, ...   \n",
       "7046176  [0, 0, 1, 1, 0, 0, 4, 1, 1, 0, 1, 0, 0, 0, 1, ...   \n",
       "7046177  [0, 0, 1, 1, 0, 0, 4, 1, 1, 0, 1, 0, 0, 0, 1, ...   \n",
       "7046178  [0, 0, 1, 1, 0, 0, 4, 1, 1, 0, 1, 0, 0, 0, 1, ...   \n",
       "7046179  [0, 0, 1, 1, 0, 0, 4, 1, 1, 0, 1, 0, 0, 0, 1, ...   \n",
       "\n",
       "                              noCap_LetterWords_inSentence  \\\n",
       "0                                                        7   \n",
       "1                                                        6   \n",
       "2                                                        1   \n",
       "3                                                        4   \n",
       "4                                                        9   \n",
       "...                                                    ...   \n",
       "7046175  [6, 7, 14, 7, 10, 9, 15, 18, 14, 1, 8, 1, 2, 1...   \n",
       "7046176  [6, 7, 14, 7, 10, 9, 15, 18, 14, 1, 8, 1, 2, 1...   \n",
       "7046177  [6, 7, 14, 7, 10, 9, 15, 18, 14, 1, 8, 1, 2, 1...   \n",
       "7046178  [6, 7, 14, 7, 10, 9, 15, 18, 14, 1, 8, 1, 2, 1...   \n",
       "7046179  [6, 7, 14, 7, 10, 9, 15, 18, 14, 1, 8, 1, 2, 1...   \n",
       "\n",
       "                                                  sim_sent  Unnamed: 0  \n",
       "0        [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...         NaN  \n",
       "1        [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...         NaN  \n",
       "2        [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...         NaN  \n",
       "3        [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...         NaN  \n",
       "4        [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...         NaN  \n",
       "...                                                    ...         ...  \n",
       "7046175                                                  0     99999.0  \n",
       "7046176                                                  1     99999.0  \n",
       "7046177                                                  0     99999.0  \n",
       "7046178                                                  0     99999.0  \n",
       "7046179                                                 1]     99999.0  \n",
       "\n",
       "[7046180 rows x 9 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = df.assign(sim_sent=df2.sim_sent.str.split(\",\")).explode('sim_sent')\n",
    "\n",
    "pd.concat([df,df3], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>summary</th>\n",
       "      <th>keywords</th>\n",
       "      <th>source1</th>\n",
       "      <th>no_words_inSent_SS</th>\n",
       "      <th>no_words_inSent_SK</th>\n",
       "      <th>noCap_LetterWords_inSentence</th>\n",
       "      <th>sim_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Minghella Sohn italienisch-schottischer Eltern...</td>\n",
       "      <td>Anthony Minghella, CBE war ein britischer Film...</td>\n",
       "      <td>oscar regie opera bbc film bestes fernsehserie...</td>\n",
       "      <td>Minghella Sohn italienisch-schottischer Eltern...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Minghella Sohn italienisch-schottischer Eltern...</td>\n",
       "      <td>Anthony Minghella, CBE war ein britischer Film...</td>\n",
       "      <td>oscar regie opera bbc film bestes fernsehserie...</td>\n",
       "      <td>Nach Schulabschluss studierte Universität Hul...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Minghella Sohn italienisch-schottischer Eltern...</td>\n",
       "      <td>Anthony Minghella, CBE war ein britischer Film...</td>\n",
       "      <td>oscar regie opera bbc film bestes fernsehserie...</td>\n",
       "      <td>1978 drehte ersten Kurzfilm .</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Minghella Sohn italienisch-schottischer Eltern...</td>\n",
       "      <td>Anthony Minghella, CBE war ein britischer Film...</td>\n",
       "      <td>oscar regie opera bbc film bestes fernsehserie...</td>\n",
       "      <td>Seit 1981 Autor Story Editor tätig .</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Minghella Sohn italienisch-schottischer Eltern...</td>\n",
       "      <td>Anthony Minghella, CBE war ein britischer Film...</td>\n",
       "      <td>oscar regie opera bbc film bestes fernsehserie...</td>\n",
       "      <td>Er wurde Theaterstücken , Rundfunkhörspielen...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>Umberto Bindi 1960er-Jahren bekanntesten Vertr...</td>\n",
       "      <td>Il mio mondo ist der Titel eines italienischsp...</td>\n",
       "      <td>my you world il re text 1964 mio song lied</td>\n",
       "      <td>Carl Sigmans Text erschien 1960er Jahren briti...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>Umberto Bindi 1960er-Jahren bekanntesten Vertr...</td>\n",
       "      <td>Il mio mondo ist der Titel eines italienischsp...</td>\n",
       "      <td>my you world il re text 1964 mio song lied</td>\n",
       "      <td>Camillo Felgen alias Heinz Helmer verfasste de...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>Umberto Bindi 1960er-Jahren bekanntesten Vertr...</td>\n",
       "      <td>Il mio mondo ist der Titel eines italienischsp...</td>\n",
       "      <td>my you world il re text 1964 mio song lied</td>\n",
       "      <td>Zahlreiche Interpreten sangen 1964 Lied franzo...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>Umberto Bindi 1960er-Jahren bekanntesten Vertr...</td>\n",
       "      <td>Il mio mondo ist der Titel eines italienischsp...</td>\n",
       "      <td>my you world il re text 1964 mio song lied</td>\n",
       "      <td>Von Letzterer stammt spanischsprachige Fassung...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>Umberto Bindi 1960er-Jahren bekanntesten Vertr...</td>\n",
       "      <td>Il mio mondo ist der Titel eines italienischsp...</td>\n",
       "      <td>my you world il re text 1964 mio song lied</td>\n",
       "      <td>In 1970er Jahren nahmen mehrere prominente Sä...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3513935 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  source  \\\n",
       "0      Minghella Sohn italienisch-schottischer Eltern...   \n",
       "0      Minghella Sohn italienisch-schottischer Eltern...   \n",
       "0      Minghella Sohn italienisch-schottischer Eltern...   \n",
       "0      Minghella Sohn italienisch-schottischer Eltern...   \n",
       "0      Minghella Sohn italienisch-schottischer Eltern...   \n",
       "...                                                  ...   \n",
       "99999  Umberto Bindi 1960er-Jahren bekanntesten Vertr...   \n",
       "99999  Umberto Bindi 1960er-Jahren bekanntesten Vertr...   \n",
       "99999  Umberto Bindi 1960er-Jahren bekanntesten Vertr...   \n",
       "99999  Umberto Bindi 1960er-Jahren bekanntesten Vertr...   \n",
       "99999  Umberto Bindi 1960er-Jahren bekanntesten Vertr...   \n",
       "\n",
       "                                                 summary  \\\n",
       "0      Anthony Minghella, CBE war ein britischer Film...   \n",
       "0      Anthony Minghella, CBE war ein britischer Film...   \n",
       "0      Anthony Minghella, CBE war ein britischer Film...   \n",
       "0      Anthony Minghella, CBE war ein britischer Film...   \n",
       "0      Anthony Minghella, CBE war ein britischer Film...   \n",
       "...                                                  ...   \n",
       "99999  Il mio mondo ist der Titel eines italienischsp...   \n",
       "99999  Il mio mondo ist der Titel eines italienischsp...   \n",
       "99999  Il mio mondo ist der Titel eines italienischsp...   \n",
       "99999  Il mio mondo ist der Titel eines italienischsp...   \n",
       "99999  Il mio mondo ist der Titel eines italienischsp...   \n",
       "\n",
       "                                                keywords  \\\n",
       "0      oscar regie opera bbc film bestes fernsehserie...   \n",
       "0      oscar regie opera bbc film bestes fernsehserie...   \n",
       "0      oscar regie opera bbc film bestes fernsehserie...   \n",
       "0      oscar regie opera bbc film bestes fernsehserie...   \n",
       "0      oscar regie opera bbc film bestes fernsehserie...   \n",
       "...                                                  ...   \n",
       "99999         my you world il re text 1964 mio song lied   \n",
       "99999         my you world il re text 1964 mio song lied   \n",
       "99999         my you world il re text 1964 mio song lied   \n",
       "99999         my you world il re text 1964 mio song lied   \n",
       "99999         my you world il re text 1964 mio song lied   \n",
       "\n",
       "                                                 source1  no_words_inSent_SS  \\\n",
       "0      Minghella Sohn italienisch-schottischer Eltern...                   1   \n",
       "0      Nach Schulabschluss studierte Universität Hul...                   0   \n",
       "0                          1978 drehte ersten Kurzfilm .                   0   \n",
       "0                  Seit 1981 Autor Story Editor tätig .                   0   \n",
       "0      Er wurde Theaterstücken , Rundfunkhörspielen...                   0   \n",
       "...                                                  ...                 ...   \n",
       "99999  Carl Sigmans Text erschien 1960er Jahren briti...                   0   \n",
       "99999  Camillo Felgen alias Heinz Helmer verfasste de...                   5   \n",
       "99999  Zahlreiche Interpreten sangen 1964 Lied franzo...                   1   \n",
       "99999  Von Letzterer stammt spanischsprachige Fassung...                   2   \n",
       "99999  In 1970er Jahren nahmen mehrere prominente Sä...                   5   \n",
       "\n",
       "       no_words_inSent_SK  noCap_LetterWords_inSentence  \\\n",
       "0                       0                             7   \n",
       "0                       0                             6   \n",
       "0                       0                             1   \n",
       "0                       0                             4   \n",
       "0                       0                             9   \n",
       "...                   ...                           ...   \n",
       "99999                   0                             7   \n",
       "99999                   1                            12   \n",
       "99999                   1                            11   \n",
       "99999                   1                             6   \n",
       "99999                   1                            13   \n",
       "\n",
       "                                                sim_sent  \n",
       "0      [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "0      [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "0      [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "0      [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "0      [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "...                                                  ...  \n",
       "99999  [1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, ...  \n",
       "99999  [1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, ...  \n",
       "99999  [1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, ...  \n",
       "99999  [1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, ...  \n",
       "99999  [1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, ...  \n",
       "\n",
       "[3513935 rows x 8 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2UpELLSEkCcp"
   },
   "outputs": [],
   "source": [
    "#df2 = pd.read_csv('/content/sample_data/data_features.csv', encoding='utf-8') \n",
    "dat = df.drop(['summary', 'keywords'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jlCr8AHPP3Wg"
   },
   "outputs": [],
   "source": [
    "def CapWords(df):\n",
    "    return sum(1 for c in df if c.isupper())\n",
    "\n",
    "df_new['noCap_LetterWords_inSentence'] = df_new['source'].apply(CapWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EaNdTR7UWaUN"
   },
   "outputs": [],
   "source": [
    "dat.to_csv('/content/sample_data/data_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nfvx7uTwtEAt"
   },
   "outputs": [],
   "source": [
    "dat.iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RXnF1R1EzHl-"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "'''X_train = np.array(sent_tokenize(dat['source'][0], language=\"german\"))\n",
    "y_train = np.array([[1],[0],[0],[0],[1],[1],[1],[1],[0],[1],[1],[0],[1],[1],[0],[1],[1],[0],[1],[0],[1],[0],[1]])\n",
    "\n",
    "X_test = np.array([\"it's a nice day in nyc\",\n",
    "                   'i loved the time i spent in london, the weather was great, though there was a nip in the air and i had to wear a jacket.'\n",
    "                   ])  ''' \n",
    "\n",
    "X_train,y_train,X_test,y_test = train_test_split(np.array(np.array(sent_tokenize(dat['source'][0], language=\"german\"))),\\\n",
    "                                                 np.array(dat['sim_sent'][0]), test_size=0.3, random_state=25)\n",
    "\n",
    "\n",
    "def get_text_length(x):\n",
    "    return np.array([len(t) for t in x]).reshape(-1, 1)\n",
    "\n",
    "classifier = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('text', Pipeline([\n",
    "            ('vectorizer', CountVectorizer(min_df=1,max_df=2)),\n",
    "            ('tfidf', TfidfTransformer()),\n",
    "        ])),\n",
    "        ('length', Pipeline([\n",
    "            ('count', FunctionTransformer(get_text_length, validate=False)),\n",
    "        ]))\n",
    "    ])),\n",
    "    ('clf', RandomForestClassifier(n_estimators = 100))])\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "predicted = classifier.predict(X_test)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eLETswaqqb0w"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "At7o3RIZTgJ9"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "d = dat[['no_words_inSent_SS', 'no_words_inSent_SK', 'noCap_LetterWords_inSentence']]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data, dat['sim_sent'],test_size=0.3, random_state=25)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "prep for classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
