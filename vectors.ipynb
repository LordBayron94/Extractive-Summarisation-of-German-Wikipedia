{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "495a8a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in h:\\anaconda\\lib\\site-packages (4.0.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in h:\\anaconda\\lib\\site-packages (from gensim) (5.1.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in h:\\anaconda\\lib\\site-packages (from gensim) (1.6.2)\n",
      "Requirement already satisfied: numpy>=1.11.3 in h:\\anaconda\\lib\\site-packages (from gensim) (1.20.1)\n",
      "Requirement already satisfied: Cython==0.29.21 in h:\\anaconda\\lib\\site-packages (from gensim) (0.29.21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\anaconda\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim\n",
    "import pandas as pd, numpy as np, gensim,nltk\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "451ba6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('G:/Extractive-Summarisation-of-German-Wikipedia/dataset/data_train.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df09ed19",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_list = nltk.corpus.stopwords.words('german')\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    filtered_words = [word for word in nltk.word_tokenize(text) if word not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_words)\n",
    "    return filtered_text\n",
    "\n",
    "df['filtered_text'] = df[\"source\"].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1dea8e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>summary</th>\n",
       "      <th>filtered_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Minghella war der Sohn italienisch-schottische...</td>\n",
       "      <td>Anthony Minghella, CBE war ein britischer Film...</td>\n",
       "      <td>Minghella Sohn italienisch-schottischer Eltern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ende der 1940er Jahre wurde eine erste Auteur-...</td>\n",
       "      <td>Die Auteur-Theorie ist eine Filmtheorie und di...</td>\n",
       "      <td>Ende 1940er Jahre wurde erste Auteur-Theorie f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Al Pacino, geboren in Manhattan, ist der Sohn ...</td>\n",
       "      <td>Alfredo James \"Al\" Pacino ist ein US-amerikani...</td>\n",
       "      <td>Al Pacino , geboren Manhattan , Sohn Salvatore...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Der Name der Alkalimetalle leitet sich von dem...</td>\n",
       "      <td>Als Alkalimetalle werden die chemischen Elemen...</td>\n",
       "      <td>Der Name Alkalimetalle leitet arabischen Wort ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Die Arbeit ist bereits seit dem Altertum Gegen...</td>\n",
       "      <td>Das deutsche Arbeitsrecht ist ein Rechtsgebiet...</td>\n",
       "      <td>Die Arbeit bereits seit Altertum Gegenstand re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  Minghella war der Sohn italienisch-schottische...   \n",
       "1  Ende der 1940er Jahre wurde eine erste Auteur-...   \n",
       "2  Al Pacino, geboren in Manhattan, ist der Sohn ...   \n",
       "3  Der Name der Alkalimetalle leitet sich von dem...   \n",
       "4  Die Arbeit ist bereits seit dem Altertum Gegen...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Anthony Minghella, CBE war ein britischer Film...   \n",
       "1  Die Auteur-Theorie ist eine Filmtheorie und di...   \n",
       "2  Alfredo James \"Al\" Pacino ist ein US-amerikani...   \n",
       "3  Als Alkalimetalle werden die chemischen Elemen...   \n",
       "4  Das deutsche Arbeitsrecht ist ein Rechtsgebiet...   \n",
       "\n",
       "                                       filtered_text  \n",
       "0  Minghella Sohn italienisch-schottischer Eltern...  \n",
       "1  Ende 1940er Jahre wurde erste Auteur-Theorie f...  \n",
       "2  Al Pacino , geboren Manhattan , Sohn Salvatore...  \n",
       "3  Der Name Alkalimetalle leitet arabischen Wort ...  \n",
       "4  Die Arbeit bereits seit Altertum Gegenstand re...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ea1f8b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Word2Vec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-5fb455011ee0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"german\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'filtered_text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"german\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m#print(model.wv.key_to_index)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mv1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Minghella'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Word2Vec' is not defined"
     ]
    }
   ],
   "source": [
    "sent = [word_tokenize(s, language=\"german\") for s in sent_tokenize(df['filtered_text'][0], language=\"german\")]\n",
    "model = Word2Vec(sent, window=5, min_count=1, workers=8)\n",
    "#print(model.wv.key_to_index)\n",
    "v1 = model.wv['Minghella']\n",
    "print (v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "889dd6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.', 'betrieben', 'Eiscreme', 'für', 'Fabrik', 'Wight', 'of', 'Isle', ',', 'Eltern', 'italienisch-schottischer', 'Sohn', 'Minghella']\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "#Change the sentences into a list of lists.\n",
    "#sent = [word_tokenize(s, language=\"german\") for s in sent_tokenize(df['filtered_text'][0], language=\"german\")]\n",
    "sentances=[]\n",
    "for s in sent_tokenize(df['filtered_text'][0], language=\"german\"):\n",
    "    sent = word_tokenize(s, language=\"german\")\n",
    "    sent =[sent[x:x+1] for x in range(0,len(sent),1)]\n",
    "    sentances.append(sent)\n",
    "#print(sentances[1])\n",
    "#model = Word2Vec(sentances[1], window=5, min_count=1, workers=8)\n",
    "#list(model.wv.key_to_index)\n",
    "models = []\n",
    "for i in range(0,len(sentances), 1):\n",
    "    #print(sentances[i])\n",
    "    model = Word2Vec(sentances[i], window=5, min_count=1, workers=8)\n",
    "    models.append(list(model.wv.key_to_index))\n",
    "#Build model\n",
    "print(models[0])\n",
    "\n",
    "#Inspect the vocabulary\n",
    "#list(model.wv.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12813c98",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'w2v' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-20331cec3904>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw2v\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'filtered_text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'w2v' is not defined"
     ]
    }
   ],
   "source": [
    "print(w2v(df['filtered_text'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2261344d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [['Al'], ['Pacino'], ['geboren'], ['Manhattan'], ['Sohn'], ['Salvatore'], ['Pacino'], ['geboren'], ['sizilianischen'], ['Stadt'], ['Corleone'], ['Rose'], ['Gerard'], ['Tochter'], ['italienischen'], ['Einwanderers'], ['italienisch-amerikanischen'], ['Mutter'], ['New'], ['York'], ['geboren'], ['wurde']]\n",
    "model = Word2Vec(text, window=5, min_count=1, workers=8)\n",
    "print(model.wv.index_to_key)\n",
    "model.wv['Sohn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49edc6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TaggedDocument(words='Minghella Sohn italienisch-schottischer Eltern , Isle of Wight Fabrik für Eiscreme betrieben .', tags=[0]), TaggedDocument(words='Nach Schulabschluss studierte Universität Hull , Zeit lang Dozent tätig .', tags=[1]), TaggedDocument(words='1978 drehte ersten Kurzfilm .', tags=[2]), TaggedDocument(words='Seit 1981 Autor Story Editor tätig .', tags=[3]), TaggedDocument(words=\"Er wurde Theaterstücken , Rundfunkhörspielen , Fernsehserie `` Inspector Morse '' vielen Drehbüchern für Film Fernsehen bekannt .\", tags=[4]), TaggedDocument(words='Er entwickelte Drehbücher für 1988 erfolgreich ausgestrahlte Fernsehserie The Storyteller Muppets-Erfinder Jim Henson .', tags=[5]), TaggedDocument(words=\"Auch Produzent erfolgreich , darunter für Filme `` Der stille Amerikaner '' , `` Die Dolmetscherin '' `` Der Vorleser '' , für 2008 posthum für Oscar nominiert wurde .\", tags=[6]), TaggedDocument(words='Gemeinsam Freund Kollegen Sydney Pollack gründete Produktionsfirma Mirage Enterprises .', tags=[7]), TaggedDocument(words=\"Der Regisseur Minghella galt guter Schauspielerführer : Unter Regie brachten zahlreiche Darsteller Oscar-Nominierungen , zwei Schauspielerinnen erhielten Auszeichnung `` Beste Nebendarstellerin '' : Juliette Binoche Renée Zellweger .\", tags=[8]), TaggedDocument(words=\"Gegen Ende Lebens kehrte Minghella Anfängen Radio Bühne zurück : 2006 wurde Hörspiel `` Eyes Down Looking '' Jude Law Ehren Samuel Beckett BBC Radio 3 ausgestrahlt , Jahr zuvor Inszenierung Puccini-Oper Madame Butterfly English National Opera London Premiere wurde Nationaloper Vilnius Metropolitan Opera New York gezeigt .\", tags=[9]), TaggedDocument(words=\"Am Ende Films `` Abbitte '' Joe Wright Kurzauftritt Talkshow-Moderator neben Vanessa Redgrave .\", tags=[10]), TaggedDocument(words=\"Seine letzte Arbeit Drehbuchautor Skript für Musical-Film `` Nine '' .\", tags=[11]), TaggedDocument(words=\"Zu letzten Regiearbeiten zählt Pilotfilm Krimiserie `` Eine Detektivin für Botswana '' , BBC fünf Tage Tod erstmals ausstrahlte .\", tags=[12]), TaggedDocument(words='Minghella Hongkong stammenden Choreographin , Produzentin Schauspielerin Carolyn Choa verheiratet .', tags=[13]), TaggedDocument(words='Der Ehe entstammen zwei Kinder , Filmbranche tätig : Tochter Hannah Minghella Produktion Sohn Max Minghella Schauspieler .', tags=[14]), TaggedDocument(words='Die Tante Edana Minghella Onkel Dominic Minghella Drehbuchautoren .', tags=[15]), TaggedDocument(words='Minghella starb Alter 54 Jahren Londoner Krankenhaus inneren Blutungen infolge Operation Tonsillenkarzinoms Karzinoms Nacken .', tags=[16]), TaggedDocument(words=\"1984 erhielt Minghella Londoner Kritikerpreis meistversprechender junger Dramatiker , 1986 Kritikerpreis für Stück `` Made Bangkok '' bestes Stück Saison .\", tags=[17]), TaggedDocument(words=\"1997 erhielt für `` Der englische Patient '' Oscar Rubrik `` Beste Regie '' , 1999 Oscar-Nominierung Kategorie `` Bestes adaptiertes Drehbuch '' für `` Der talentierte Mr.\", tags=[18]), TaggedDocument(words=\"Ripley '' , Regie führte .\", tags=[19]), TaggedDocument(words='2001 wurde Minghella Commander of the British Empire ernannt .', tags=[20]), TaggedDocument(words='Von 2003 2007 Präsident British Film Institute .', tags=[21]), TaggedDocument(words='Seit 1997 trägt Anthony Minghella Theatre Isle of Wight Namen .', tags=[22])]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "doc= df['filtered_text'][0]\n",
    "#token_doc = []\n",
    "#for i in doc:\n",
    "#    token_doc.append(word_tokenize(i, language=\"german\"))\n",
    "sent = sent_tokenize(doc, language=\"german\")\n",
    "tagged_data = [TaggedDocument(d, [i]) for i, d in enumerate(sent)]\n",
    "model = Doc2Vec(tagged_data, window=2, min_count=1, workers=8)\n",
    "print(tagged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dcf02e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8acb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['source'][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
