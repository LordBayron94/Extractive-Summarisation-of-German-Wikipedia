{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72bc62bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\anaconda\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec, word2vec\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.pipeline import Pipeline\n",
    "import sqlite3\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b90a57b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>source</th>\n",
       "      <th>no_words_inSent_SS</th>\n",
       "      <th>no_words_inSent_SK</th>\n",
       "      <th>sim_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Minghella Sohn italienisch-schottischer Eltern...</td>\n",
       "      <td>[[1], [0], [0], [0], [0], [0], [0], [0], [1], ...</td>\n",
       "      <td>[[0], [0], [0], [0], [0], [0], [0], [0], [0], ...</td>\n",
       "      <td>[[1], [0], [0], [0], [0], [0], [1], [0], [0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Ende 1940er Jahre wurde erste Auteur-Theorie f...</td>\n",
       "      <td>[[2], [1], [0], [1], [0], [1], [0], [2], [1], ...</td>\n",
       "      <td>[[0], [0], [0], [0], [0], [0], [0], [0], [0], ...</td>\n",
       "      <td>[[0], [0], [0], [0], [0], [1], [1], [1], [1], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Al Pacino , geboren Manhattan , Sohn Salvatore...</td>\n",
       "      <td>[[4], [0], [2], [1], [2], [1], [0], [2], [4], ...</td>\n",
       "      <td>[[0], [0], [0], [1], [1], [0], [0], [0], [0], ...</td>\n",
       "      <td>[[1], [0], [1], [1], [1], [1], [0], [0], [0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Der Name Alkalimetalle leitet arabischen Wort ...</td>\n",
       "      <td>[[1], [1], [0], [0], [1], [2], [1], [1], [1], ...</td>\n",
       "      <td>[[0], [0], [0], [0], [0], [0], [0], [0], [0], ...</td>\n",
       "      <td>[[0], [0], [0], [0], [0], [0], [0], [0], [1], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Die Arbeit bereits seit Altertum Gegenstand re...</td>\n",
       "      <td>[[0], [0], [0], [0], [0], [0], [0], [2], [0], ...</td>\n",
       "      <td>[[0], [0], [0], [0], [0], [0], [0], [0], [0], ...</td>\n",
       "      <td>[[1], [1], [0], [1], [0], [0], [0], [0], [1], ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             source  \\\n",
       "0           0  Minghella Sohn italienisch-schottischer Eltern...   \n",
       "1           1  Ende 1940er Jahre wurde erste Auteur-Theorie f...   \n",
       "2           2  Al Pacino , geboren Manhattan , Sohn Salvatore...   \n",
       "3           3  Der Name Alkalimetalle leitet arabischen Wort ...   \n",
       "4           4  Die Arbeit bereits seit Altertum Gegenstand re...   \n",
       "\n",
       "                                  no_words_inSent_SS  \\\n",
       "0  [[1], [0], [0], [0], [0], [0], [0], [0], [1], ...   \n",
       "1  [[2], [1], [0], [1], [0], [1], [0], [2], [1], ...   \n",
       "2  [[4], [0], [2], [1], [2], [1], [0], [2], [4], ...   \n",
       "3  [[1], [1], [0], [0], [1], [2], [1], [1], [1], ...   \n",
       "4  [[0], [0], [0], [0], [0], [0], [0], [2], [0], ...   \n",
       "\n",
       "                                  no_words_inSent_SK  \\\n",
       "0  [[0], [0], [0], [0], [0], [0], [0], [0], [0], ...   \n",
       "1  [[0], [0], [0], [0], [0], [0], [0], [0], [0], ...   \n",
       "2  [[0], [0], [0], [1], [1], [0], [0], [0], [0], ...   \n",
       "3  [[0], [0], [0], [0], [0], [0], [0], [0], [0], ...   \n",
       "4  [[0], [0], [0], [0], [0], [0], [0], [0], [0], ...   \n",
       "\n",
       "                                            sim_sent  \n",
       "0  [[1], [0], [0], [0], [0], [0], [1], [0], [0], ...  \n",
       "1  [[0], [0], [0], [0], [0], [1], [1], [1], [1], ...  \n",
       "2  [[1], [0], [1], [1], [1], [1], [0], [0], [0], ...  \n",
       "3  [[0], [0], [0], [0], [0], [0], [0], [0], [1], ...  \n",
       "4  [[1], [1], [0], [1], [0], [0], [0], [0], [1], ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('G:/Extractive-Summarisation-of-German-Wikipedia/dataset/data_features.csv', encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2de80d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.head(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9c7ef6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = data.source, data.sim_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4e2e8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "def identify_tokens(row):\n",
    "    tokens = sent_tokenize(row, language='german')\n",
    "    return tokens\n",
    "X = X.apply(identify_tokens)\n",
    "y = y.apply(identify_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "384f05c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=X, window=4, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05786bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_vector(word2vec_model, doc):\n",
    "    # remove out-of-vocabulary words\n",
    "    doc = [word for word in doc if word in model.wv.key_to_index]\n",
    "    return np.mean(model[doc], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28198c69",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Word2Vec' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-06fe7fa88739>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# append the vector for each document\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mlst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocument_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-14-4e715a8be4a9>\u001b[0m in \u001b[0;36mdocument_vector\u001b[1;34m(word2vec_model, doc)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m# remove out-of-vocabulary words\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey_to_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'Word2Vec' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "lst=[]\n",
    "for doc in X: # append the vector for each document\n",
    "    lst.append(document_vector(model, doc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
